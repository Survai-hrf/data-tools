{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "import argparse\n",
    "import os\n",
    "from pytube import YouTube\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "import pandas as pd\n",
    "from pytube.exceptions import VideoUnavailable\n",
    "import distutils.dir_util\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'gcloud-connect.json'\n",
    "storage_client = storage.Client()\n",
    "my_bucket = storage_client.get_bucket('js_test_bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to download videos\n",
    "def download(url, file_name, start, end, fill_start, fill_end):\n",
    "    attempts = 0\n",
    "    while attempts < 3: \n",
    "        try: \n",
    "            video = YouTube(url)\n",
    "            yt_video = video.streams.get_highest_resolution()\n",
    "            yt_video.download(output_path='', filename=f\"{file_name}.mp4\")\n",
    "            ffmpeg_extract_subclip(filename=f'{file_name}.mp4', t1=start, t2=end, \n",
    "                                    targetname=f'{file_name}_{fill_start}_{fill_end}.mp4') \n",
    "            os.remove(f'{file_name}.mp4') \n",
    "            break\n",
    "        except:\n",
    "            print('retrying...', file_name)\n",
    "            attempts += 1\n",
    "            continue\n",
    "    else:  \n",
    "        print('BROKEN VIDEO: ', file_name)\n",
    "        broken_videos.append(file_name) # add broken videos to array to be deleted\n",
    "    \n",
    "# function to upload videos to gcloud bucket\n",
    "def upload_to_bucket(blob_name, file_path, bucket_name):\n",
    "    try:\n",
    "        bucket = storage_client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        blob.upload_from_filename(file_path)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'var_data.csv'\n",
    "split_path = 'split'\n",
    "clarity_level = ['easy', 'medium', 'hard', 'none', 'bad']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n",
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "blobs = my_bucket.list_blobs(prefix='split/')\n",
    "for blob in blobs: blob.delete()\n",
    "\n",
    "# Read csv, clean data\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df.reset_index()\n",
    "df['clarity_level'] = df['clarity_level'].fillna('none') \n",
    "df['split'] = 'train'\n",
    "df = df.head(20)\n",
    "\n",
    "# open label_map.txt, create list of labels with their index as key\n",
    "txt = open('label_map.txt', 'r')\n",
    "lines = [s.strip('\\n')for s in txt]\n",
    "txt.close()\n",
    "label_map = dict((index, label) for label, index in enumerate(lines, start=1))\n",
    "broken_videos = []\n",
    "\n",
    "# iterates all videos in df and downloads them to 'master_videos' folder\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    file_name = str(row['id'])\n",
    "    start = int(row['time_start'])\n",
    "    end = int(row['time_end'])\n",
    "    label = str(row['label'])\n",
    "    url = f'https://www.youtube.com/watch?v={file_name[0:11]}'\n",
    "    fill_start = str(start).zfill(6) # make times the same number of digits\n",
    "    fill_end = str(end).zfill(6)\n",
    "\n",
    "    # ignore bad labels and bad videos\n",
    "    if label not in label_map.keys(): \n",
    "        df.drop(index, inplace=True)\n",
    "        continue \n",
    "    \n",
    "    # check if file already exists in gcloud storage bucket\n",
    "    videos = storage_client.list_blobs('js_test_bucket')\n",
    "    video_list = [video.name for video in videos]\n",
    "    if f\"master_videos/{label}/{file_name}_{fill_start}_{fill_end}.mp4\" in video_list:\n",
    "        print('file already exists')\n",
    "        continue\n",
    "    \n",
    "    download(url, file_name, start, end, fill_start, fill_end)\n",
    "    upload_to_bucket(f'master_videos/{label}/{file_name}_{fill_start}_{fill_end}.mp4', \n",
    "                        f\"{file_name}_{fill_start}_{fill_end}.mp4\", 'js_test_bucket')\n",
    "    os.remove(f\"{file_name}_{fill_start}_{fill_end}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter df and create train and val split\n",
    "for video in broken_videos: \n",
    "    df = df.drop(df.loc[df['id'] == video].index) # drop videos from df that did not download\n",
    "\n",
    "# drop rows with clarity levels not included in list of clarity levels\n",
    "for index, row in df.iterrows(): \n",
    "    if row['clarity_level'] not in clarity_level: df.drop(index, inplace=True) \n",
    "\n",
    "# set val split for each class equal to 35% of the class with the least amount of rows\n",
    "least_label = int(df['label'].value_counts().min()*0.35) \n",
    "df_val = df.groupby('label').apply(lambda x: x.sample(n=1, replace=False)) \n",
    "df_val['split'] = 'val'\n",
    "cond = df['id'].isin(df_val['id'])\n",
    "df.drop(df[cond].index, inplace = True)\n",
    "df = pd.concat([df, df_val], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = []\n",
    "train_list = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    file_name = str(row['id'])\n",
    "    start = int(row['time_start'])\n",
    "    end = int(row['time_end'])\n",
    "    label = str(row['label'])\n",
    "    url = f'https://www.youtube.com/watch?v={file_name[0:11]}'\n",
    "    fill_start = str(start).zfill(6) # make times the same number of digits\n",
    "    fill_end = str(end).zfill(6)\n",
    "    class_num = label_map.get(label)\n",
    "    split = row['split']\n",
    "\n",
    "    source_bucket = storage_client.bucket('js_test_bucket')\n",
    "    source_blob = source_bucket.blob(f\"master_videos/{label}/{file_name}_{fill_start}_{fill_end}.mp4\")\n",
    "\n",
    "    if split == 'val':\n",
    "        source_bucket.copy_blob(source_blob, source_bucket, f\"{split_path}/val/{label}/{file_name}_{fill_start}_{fill_end}.mp4\")\n",
    "        val_list.append(f\"{label}/{file_name}_{fill_start}_{fill_end}.mp4 {class_num}\")\n",
    "        \n",
    "    if split == 'train':\n",
    "        source_bucket.copy_blob(source_blob, source_bucket, f\"{split_path}/train/{label}/{file_name}_{fill_start}_{fill_end}.mp4\")\n",
    "        train_list.append(f\"{label}/{file_name}_{fill_start}_{fill_end}.mp4 {class_num}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create val_list and train_list txt's  \n",
    "with open('val_list.txt', 'w') as val_file, open('train_list.txt', 'w') as train_file:\n",
    "    for file_name in val_list:\n",
    "        val_file.write(f\"{file_name}\\n\")\n",
    "    for file_name in train_list:\n",
    "        train_file.write(f\"{file_name}\\n\")\n",
    "\n",
    "upload_to_bucket('split/val_list.txt', 'val_list.txt', 'js_test_bucket')\n",
    "upload_to_bucket('split/train_list.txt', 'train_list.txt', 'js_test_bucket')\n",
    "os.remove('val_list.txt')\n",
    "os.remove('train_list.txt')    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f0d9b29d3abf450bf16b2b0a1c26e44348ebdbb4c4f2d61ade5ad73213c2959"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dsbasic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
