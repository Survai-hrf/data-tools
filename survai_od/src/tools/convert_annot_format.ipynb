{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTURK to COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final csv\n",
    "CSV_PATH = \"../LEGACY_test/JACKSON_APPROVED_10_5.csv\"\n",
    "\n",
    "#output path for JSON in COCO format, include file name\n",
    "JSON_OUTPUT_PATH = \"../LEGACY_test/JACKSON_APPROVED_10_5_coco.json\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "\n",
    "# only approved\n",
    "df = df[df['jackson_approve'] == 'x']\n",
    "\n",
    "json_out = {\"info\": {}, \"licenses\": [], \"categories\": [{\"id\":1,\"name\":\"Officer\"},{\"id\":2,\"name\":\"Civilian\"},{\"id\":3,\"name\":\"Riot Shield\"},{\"id\":4,\"name\":\"Gun\"},{\"id\":5,\"name\":\"Pepper Spray\"},{\"id\":6,\"name\":\"Baton\"}], \"images\": [], \"annotations\": []}\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the images section\n",
    "sub_df = df[['Input.image_url', 'Answer.annotatedResult.inputImageProperties.height', 'Answer.annotatedResult.inputImageProperties.width']]\n",
    "\n",
    "i = 0\n",
    "for row in sub_df.iterrows():\n",
    "    json_out['images'].append({\"id\": i, \"file_name\": row[1][0].split('/')[-1], \"height\": row[1][1], \"width\": row[1][2]})\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the annotations section \n",
    "\n",
    "id = 0\n",
    "image_id = 0\n",
    "\n",
    "for item in df['Answer.annotatedResult.polygons'].iteritems():\n",
    "\n",
    "    item = eval(item[1])\n",
    "\n",
    "    #go through each annotation in one row\n",
    "    for i in range(len(item)):\n",
    "\n",
    "        #skip deleted annotations\n",
    "        if item[i]['label'] == '':\n",
    "            continue\n",
    "            \n",
    "        category_id = item[i]['label']\n",
    "        category_id = [i['id'] for i in json_out['categories'] if category_id in i['name']][0]\n",
    "\n",
    "        segmentation = []\n",
    "    \n",
    "        #go through each vertices in one annotation\n",
    "        for j in item[i]['vertices']:\n",
    "            \n",
    "            segmentation.append(j['x'])\n",
    "            segmentation.append(j['y'])\n",
    "\n",
    "        #if list not empty    \n",
    "        if bool(segmentation):\n",
    "            segmentation.append(segmentation[0])\n",
    "            segmentation.append(segmentation[1])\n",
    "\n",
    "            #generate bboxes\n",
    "            bbox = []\n",
    "            highest_y = int\n",
    "            highest_x = int\n",
    "            lowest_y = int\n",
    "            lowest_x = int\n",
    "            for k in range(len(segmentation)):\n",
    "                \n",
    "                if k == 0:\n",
    "                    topleft_pair = [segmentation[k], segmentation[k+1]]\n",
    "                    highest_x = topleft_pair[0]\n",
    "                    lowest_x = topleft_pair[0]\n",
    "                    lowest_y = topleft_pair[1]\n",
    "                    highest_y = topleft_pair[1]\n",
    "\n",
    "                if k % 2:\n",
    "                    continue\n",
    "                \n",
    "                if k + 1 <= len(segmentation):\n",
    "                    pair = [segmentation[k], segmentation[k+1]]\n",
    "\n",
    "                    if pair[0] > highest_x:\n",
    "                        highest_x = pair[0]\n",
    "                    elif pair[0] < lowest_x:\n",
    "                        lowest_x = pair[0]\n",
    "\n",
    "                    if pair[1] < lowest_y:\n",
    "                        lowest_y = pair[1]\n",
    "                    elif pair[1] > highest_y:\n",
    "                        highest_y = pair[1]\n",
    "      \n",
    "        \n",
    "            #POSSIBLE ERROR HERE. BY NESTING THIS LINE IN THE FOR LOOP HERE, IT MAY CAUSE ERROR BY NOT APPENDING AN ID WHEN EMPTY LIST \n",
    "            json_out['annotations'].append({\"id\": id, \"iscrowd\": 0, \"image_id\": image_id, \"category_id\":category_id, \n",
    "                    \"segmentation\": [segmentation], \"bbox\": [lowest_x, lowest_y, highest_x-lowest_x, highest_y-lowest_y], })\n",
    "\n",
    "        id += 1\n",
    "        \n",
    "    image_id += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save json COCO to output path\n",
    "with open(JSON_OUTPUT_PATH, 'w') as f:\n",
    "    json.dump(json_out, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_out['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COCO FORMAT:\n",
    "{\n",
    "    \"info\": {},\n",
    "    \"licenses\": [],\n",
    "    \"categories\": [\n",
    "        ...\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"name\": \"cat\",\n",
    "            \"supercategory\": \"animal\"\n",
    "        },\n",
    "        ...\n",
    "    ],\n",
    "    \"images\": [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"file_name\": \"<filename0>.<ext>\",\n",
    "            \"height\": 480,\n",
    "            \"width\": 640,\n",
    "        },\n",
    "        ...\n",
    "    ],\n",
    "    \"annotations\": [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"image_id\": 0,\n",
    "            \"category_id\": 2,\n",
    "            \"bbox\": [260, 177, 231, 199] ,\n",
    "            \"segmentation\": [...],\n",
    "            \"area\": 45969,\n",
    "            \"iscrowd\": 0\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "\"categories\": [{\"id\":1,\"name\":\"Officer\"}, ...]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO TO VIA VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert coco format into useable VIA/vgg format\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "json_file = open(\"../data/annotations/guns/0-873.json\")\n",
    "#json_file2 = open(\"\")\n",
    "j = json.load(json_file)\n",
    "json_file.close()\n",
    "#json_file2.close()\n",
    "\n",
    "\"\"\"\n",
    "COCO\n",
    "{\n",
    "\"info\": {},\n",
    "\"images\": [{}, {}]\n",
    "\"annotations\"[{}, {}]:\n",
    "\"categories\":[{},{}]\n",
    "}:\n",
    "\n",
    "VGG\n",
    "{ 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "    'regions': {\n",
    "        '0': {\n",
    "            'region_attributes': {'name'=int},\n",
    "            'shape_attributes': {\n",
    "                'all_points_x': [...],\n",
    "                'all_points_y': [...],\n",
    "                'name': 'polygon'}},\n",
    "        ... more regions ...\n",
    "    },\n",
    "    'size': 100202\n",
    "    }\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Get ID's from coco's split data storage of annotations to match and into the same object\n",
    "\n",
    "matching_ids = {}\n",
    "\n",
    "for i, val in enumerate(j['annotations']):\n",
    "     \n",
    "    #add item label to url\n",
    "    image_id = j['annotations'][i]['image_id']\n",
    "    matching_ids[i] = []\n",
    "    matching_ids[i].append(val)\n",
    "\n",
    "    v = 0\n",
    "    for u, val in enumerate(j['annotations']):\n",
    "        if j['annotations'][u]['image_id'] == image_id and u != i:\n",
    "            \n",
    "            matching_ids[i].append(val)\n",
    "\n",
    "#combine image_ids\n",
    "image_id_list = []           \n",
    "for i, val in enumerate(matching_ids.copy()):\n",
    "    if j['annotations'][i]['image_id'] in image_id_list:\n",
    "        del matching_ids[i]\n",
    "\n",
    "    else:\n",
    "        image_id_list.append(j['annotations'][i]['image_id'])\n",
    "    \n",
    "#make id match image_id\n",
    "for i, val in enumerate(matching_ids.copy()):\n",
    "    i = i+1\n",
    "\n",
    "    matching_ids[i] = matching_ids[val]\n",
    "    del matching_ids[val]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Assemble all annotations into a via/vgg list saved as \"k\"\n",
    "k={}\n",
    "\n",
    "for i, image in enumerate(j['images']):\n",
    "\n",
    "    #filename\n",
    "    file_name_id = {'file_name' : str, 'id': int, 'width': int, 'height': int, 'regions': {}}\n",
    "\n",
    "    \n",
    "\n",
    "    file_name_id['file_name'] = string +j['images'][i]['file_name'][0:63]\n",
    "    file_name_id['id'] = j['images'][i]['id']\n",
    "    file_name_id['width'] = j['images'][i]['width']\n",
    "    file_name_id['height'] = j['images'][i]['height']\n",
    "    #update with filename\n",
    "    k.update({i: file_name_id})\n",
    "    \n",
    "    #add category and x and y\n",
    "for ind, image in enumerate(k):\n",
    "    \n",
    "    for ind2, annot in enumerate(matching_ids[ind+1]):\n",
    "        #go through each annotation for every image and append all x and y and category ids\n",
    "\n",
    "        #get x and y points\n",
    "        all_x =[]\n",
    "        all_y = []\n",
    "\n",
    "        for ind3, num in enumerate(annot['segmentation'][0]):\n",
    "            if ind3 % 2 == 0:\n",
    "                all_x.append(num)\n",
    "            if ind3 % 2 == 1:\n",
    "                all_y.append(num)\n",
    "        # get first x and y to append at end of points to match via vgg format\n",
    "        all_x.append(all_x[0])\n",
    "        all_y.append(all_y[0])  \n",
    "\n",
    "        #change name of category to string\n",
    "        category = annot['category_id']\n",
    "        if category == 1:\n",
    "            category = 'Officer'\n",
    "        if category == 2:\n",
    "            category = 'Civilian'\n",
    "        if category == 3:\n",
    "            category = 'Gun'\n",
    "        if category == 4:\n",
    "            category = 'Baton'\n",
    "        if category == 5:\n",
    "            category = 'Riot Shield'\n",
    "        if category == 6:\n",
    "            category = 'Pepper Spray'\n",
    "\n",
    "    #add first num to end\n",
    "        k[ind]['regions'][ind2] = {'region_attributes': {'name': category}, 'shape_attributes': {'all_points_x': all_x,'all_points_y': all_y}}\n",
    "\n",
    "     \n",
    "\n",
    "        # Load annotations\n",
    "        # VGG Image Annotator (up to version 1.6) saves each image in the form:\n",
    "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "        #   'regions': {\n",
    "        #       '0': {\n",
    "        #           'region_attributes': {},\n",
    "        #           'shape_attributes': {\n",
    "        #               'all_points_x': [...],\n",
    "        #               'all_points_y': [...],\n",
    "        #               'name': 'polygon'}},\n",
    "        #       ... more regions ...\n",
    "        #   },\n",
    "        #   'size': 100202\n",
    "        # }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split for training and val\n",
    "val_len = round(len(k) * 0.177) #int with val size\n",
    "\n",
    "val = dict(list(k.items())[len(k)-val_len:])\n",
    "train = dict(list(k.items())[:len(k)-val_len])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save master, not train val split\n",
    "with open('../data/annotations/masters/05_24_coco.json', 'w') as f:\n",
    "    json.dump(k, f)\n",
    "#Save K as JSON object\n",
    "#update with path for upload\n",
    "#train\n",
    "\"\"\"with open('../source/Mask_RCNN/datasets/proto/train/via_region_data.json', 'w') as f:\n",
    "    json.dump(train, f)\n",
    "#val\n",
    "with open('../source/Mask_RCNN/datasets/proto/val/via_region_data.json', 'w') as f:\n",
    "    json.dump(val, f)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert mturk csv to VIA VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "# PARAMS\n",
    "###########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "#final csvs\n",
    "final_csv = \"../data/annotation_csvs/combined_csvs/MASTER_0707.csv\"\n",
    "\n",
    "#either g, ps, b for different objects, MAKE THIS STRING EMPTY FOR RIOT SHIELDS!!!!\n",
    "starting_letter_id = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(final_csv)\n",
    "obj = {} #dict to fill \n",
    "\n",
    "#loads a reference obj in perfect shape\n",
    "json_file2 = open(\"../source/Mask_RCNN/datasets/proto/val/via_region_data.json\")\n",
    "\n",
    "ref = json.load(json_file2) #vgg annot\n",
    "json_file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(\"nan\", \"\")\n",
    "\n",
    "#df = df.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1','Unnamed: 0.1.1.1', 'Unnamed: 0.1.1.1.1'], axis=1)\n",
    "\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "approved = df#[df['Approve'] == 'x']\n",
    "\n",
    "#randomize rows\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place format and file info into object\n",
    "\n",
    "for i, row in approved.iterrows():\n",
    "    image_name_loc = approved['Input.image_url'][i].find('images/') + 7\n",
    "    file_name_id = {'file_name' : str, 'width': int, 'height': int, 'regions': {}}\n",
    "    file_name_id['file_name'] = starting_letter_id + approved['Input.image_url'][i][image_name_loc:]\n",
    "    file_name_id['height'] = int(approved['Answer.annotatedResult.inputImageProperties.height'][i])\n",
    "    file_name_id['width'] = int(approved['Answer.annotatedResult.inputImageProperties.width'][i])\n",
    "\n",
    "    #update with filename\n",
    "    obj.update({i: file_name_id})   \n",
    "    the_annot = eval(approved['Answer.annotatedResult.polygons'][i])\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    'regions': {'0': {'region_attributes': {'name': 'Civilian'},\n",
    "        'shape_attributes': {'all_points_x': [141.53846153846155,\n",
    "        141.53846153846155],\n",
    "        'all_points_y': [224.6153846153846,\n",
    "        224.6153846153846]}},\n",
    "    '1': {'region_attributes': {'name': 'Civilian'},\n",
    "        'shape_attributes': {'all_points_x': [777.4358974358975,\n",
    "        777.4358974358975],\n",
    "        'all_points_y': [205.47008547008548,\n",
    "        205.47008547008548]}},\n",
    "    '2': {'region_attributes': {'name': 'Gun'},\n",
    "        'shape_attributes': {'all_points_x': [633.1623931623932,\n",
    "        659.8290598290598],\n",
    "        'all_points_y': [120.68376068376068]}}}}\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "    for j in range(0, len(the_annot)):\n",
    "        #contains a single classified annotation\n",
    "        label = the_annot[j]['label']\n",
    "        if label == '':\n",
    "            continue\n",
    "        all_x = []\n",
    "        all_y = []\n",
    "        \n",
    "        #for every vertices inside a single label\n",
    "        for v in the_annot[j]['vertices']:\n",
    "            all_x.append(v['x'])\n",
    "            all_y.append(v['y'])\n",
    "\n",
    "        # get first x and y to append at end of points to match via vgg format\n",
    "\n",
    "        #account for empty annotatins\n",
    "        if all_x:\n",
    "            all_x.append(all_x[0])\n",
    "        else:\n",
    "            pass\n",
    "        if all_y:\n",
    "            all_y.append(all_y[0])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        obj[i]['regions'][j] = {'region_attributes': {'name': label}, 'shape_attributes': {'all_points_x': all_x,'all_points_y': all_y}}\n",
    "\n",
    "\n",
    "\n",
    "    #add first num to end\n",
    "        #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split for training and val\n",
    "val_len = round(len(obj) * 0.177) #int with val size\n",
    "\n",
    "val = dict(list(obj.items())[len(obj)-val_len:])\n",
    "train = dict(list(obj.items())[:len(obj)-val_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5213"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final object as JSON object\n",
    "with open('../data/annotations/masters/0707_csv.json', 'w') as f:\n",
    "    json.dump(obj, f)\n",
    "\n",
    "\n",
    "\n",
    "#update with path for upload\n",
    "\n",
    "#train\n",
    "with open('../source/Mask_RCNN/datasets/mk2/train/via_region_data.json', 'w') as f:\n",
    "    json.dump(train, f)\n",
    "#val\n",
    "with open('../source/Mask_RCNN/datasets/mk2/val/via_region_data.json', 'w') as f:\n",
    "    json.dump(val, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine coco jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add names/paths of jsons you want to combine\n",
    "jsons = ['general_0-1000-16-coco.json', 'general-0-129-1175-coco.json',\n",
    "         'gun-0-873.json', 'JACKSON_APPROVED_10_5_coco.json', 'teargas_20000-22654-coco.json',\n",
    "          'teargas_22654-23400-coco.json', 'teargas_23400-23453-coco.json']\n",
    "\n",
    "# make a master json start as first element in jsons list\n",
    "with open(jsons[0]) as json_file:\n",
    "    master_json = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "JSON_MASTER_PATH = \"general_0-1000-16-coco.json\"\n",
    "JSON_PATH_2 = \"general-0-129-1175-coco.json\"\n",
    "\n",
    "with open(JSON_MASTER_PATH) as json_file:\n",
    "    json_1 = json.load(json_file)\n",
    "with open(JSON_PATH_2) as json_file:\n",
    "    json_2 = json.load(json_file)\n",
    " #vgg annot\n",
    "\n",
    "max_len_1 = len(json_1) - 1\n",
    "\n",
    "max_len_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change keys of second json to start after \n",
    "new_json = {}\n",
    "\n",
    "for key, val in json_2.items():\n",
    "    new_json[str(max_len_1+1 + int(key))] = json_2[key]\n",
    "\n",
    "json_2 = new_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_json = dict(json_1, **json_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/annotations/masters/0707_merged.json', 'w') as f:\n",
    "    json.dump(merged_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train val split a master VOC json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "JSON_PATH = \"../data/annotations/masters/0707_merged.json\"\n",
    "\n",
    "\n",
    "with open(JSON_PATH) as json_file:\n",
    "    master_json = json.load(json_file)\n",
    "\n",
    "\n",
    "#Split for training and val\n",
    "val_len = round(len(master_json) * 0.177) #int with val size\n",
    "val = dict(list(master_json.items())[len(master_json)-val_len:])\n",
    "train = dict(list(master_json.items())[:len(master_json)-val_len])\n",
    "\n",
    "#update with path for upload\n",
    "#train\n",
    "with open('../source/Mask_RCNN/datasets/mk2/train/via_region_data.json', 'w') as f:\n",
    "    json.dump(train, f)\n",
    "#val\n",
    "with open('../source/Mask_RCNN/datasets/mk2/val/via_region_data.json', 'w') as f:\n",
    "    json.dump(val, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Val Test Split COCO json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "JSON_PATH = \"completed_annotations/masters/master_mod.json\"\n",
    "\n",
    "with open(JSON_PATH) as json_file:\n",
    "    master_json = json_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(master_json, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "940bfbe886eb20a7b826d584bab44034bfef0a3399bb3c8ee6af20f950f5c0f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('hrf_od': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
